{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from scipy.sparse import hstack,vstack,csr_matrix,save_npz,load_npz\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "\n",
    "############################################################################\n",
    "#----- work folder -----\n",
    "############################################################################\n",
    "settings = json.load(open('./settings.json'))\n",
    "\n",
    "input_path = settings['input_path']\n",
    "features_path = settings['features_path']\n",
    "model_path = settings['model_path']\n",
    "sub_path = settings['sub_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load raw count and raw target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_df = pd.read_feather(feature_path+'train_cite_inputs_id.feather')\n",
    "test_df = pd.read_feather(feature_path+'test_cite_inputs_id.feather')\n",
    "\n",
    "cite_inputs_sparse = load_npz(feature_path+\"cite_inputs_raw_sparse.npz\")\n",
    "\n",
    "train_cite_X = cite_inputs_sparse[:len(train_df)]\n",
    "test_cite_X = cite_inputs_sparse[len(train_df):]\n",
    "\n",
    "train_cite_y = pd.read_hdf(input_path+'train_cite_targets_raw.h5').values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cite_X.shape,test_cite_X.shape,train_cite_y.shape,cite_inputs_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ====================================================\n",
    "# lightgbm\n",
    "# ====================================================\n",
    "def lgb_kfold(train_df, test_df, train_cite_X, train_cite_y, test_cite_X, folds):\n",
    "    params = {    \n",
    "        'objective' : 'rmse',\n",
    "        'metric' : 'mse', \n",
    "         'num_leaves': 33,\n",
    "         'min_data_in_leaf': 30,\n",
    "         'learning_rate': 0.01,\n",
    "         'max_depth': 7,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.1,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"lambda_l1\":1,\n",
    "         \"lambda_l2\":10,\n",
    "         \"verbosity\": -1,        \n",
    "                 }      \n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df)): \n",
    "        print ('n_fold:',n_fold)\n",
    "        train_x = train_cite_X[train_idx]\n",
    "        valid_x = train_cite_X[valid_idx]\n",
    "        train_y = train_cite_y[train_idx]\n",
    "        valid_y = train_cite_y[valid_idx]\n",
    "\n",
    "        dtrain = lgb.Dataset(\n",
    "            train_x, label=train_y,)\n",
    "        dval = lgb.Dataset(\n",
    "            valid_x, label=valid_y, reference=dtrain,)\n",
    "        bst = lgb.train(\n",
    "            params, dtrain, num_boost_round=10000,\n",
    "            valid_sets=[dval],verbose_eval=1000, early_stopping_rounds=100,\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds += bst.predict(test_cite_X, num_iteration=bst.best_iteration) / folds.n_splits         \n",
    "        \n",
    "    return oof_preds,sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 666\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=seed)  \n",
    "train_preds = []\n",
    "test_preds = []\n",
    "for i in range(140):\n",
    "    print('=====================')\n",
    "    print(i)\n",
    "    train_cite_y_single = train_cite_y[:,i]\n",
    "    oof_preds,sub_preds = lgb_kfold(train_df, test_df, train_cite_X, train_cite_y_single, test_cite_X, folds)\n",
    "    train_preds.append(oof_preds)\n",
    "    test_preds.append(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "oof_preds = np.zeros((len(train_df), 140))\n",
    "for n in range(len(train_preds)):\n",
    "    oof_preds[:,n] =  train_preds[n]\n",
    "\n",
    "sub_preds = np.zeros((48203, 140))\n",
    "for n in range(len(test_preds)):\n",
    "    sub_preds[:,n] =  test_preds[n]  \n",
    "\n",
    "lgb4 = np.concatenate([oof_preds,sub_preds],axis=0)\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=100, algorithm='arpack')\n",
    "lgb4_svd = tsvd.fit_transform(lgb4)\n",
    "np.save(feature_path+'cite_lgb4_svd_100.npy', lgb4_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
