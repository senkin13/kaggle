{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from scipy.sparse import hstack,vstack,csr_matrix,save_npz,load_npz\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "\n",
    "############################################################################\n",
    "#----- work folder -----\n",
    "############################################################################\n",
    "settings = json.load(open('./settings.json'))\n",
    "\n",
    "input_path = settings['input_path']\n",
    "features_path = settings['features_path']\n",
    "model_path = settings['model_path']\n",
    "sub_path = settings['sub_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load clr svd,fine tuned process,correlated and important feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('modify test')\n",
    "test_cite_inputs = pd.read_hdf(input_path+'test_cite_inputs.h5').reset_index()[['cell_id']]\n",
    "test_cite_inputs_raw = pd.read_hdf(input_path+'test_cite_inputs_raw.h5').reset_index()\n",
    "\n",
    "print('target')\n",
    "train_df = pd.read_feather(feature_path+'train_cite_inputs_id.feather')\n",
    "test_df = pd.read_feather(feature_path+'test_cite_inputs_id.feather')\n",
    "\n",
    "train_cite_y = np.load(feature_path+'train_cite_targets.npy')    \n",
    "\n",
    "print('cite_inputs_svd_clr')\n",
    "cite_inputs_svd_clr = np.load(feature_path+'cite_inputs_svd_clr_200.npy')\n",
    "train_cite_svd_clr = cite_inputs_svd_clr[:len(train_df)]\n",
    "test_cite_svd_clr = cite_inputs_svd_clr[len(train_df):]\n",
    "\n",
    "df_test_cite_svd_clr = pd.DataFrame(test_cite_svd_clr)\n",
    "df_test_cite_svd_clr['cell_id'] = test_cite_inputs_raw['cell_id']\n",
    "test_cite_inputs_id = test_cite_inputs.copy()\n",
    "test_cite_inputs_id = test_cite_inputs_id.merge(df_test_cite_svd_clr, on=['cell_id'], how='left')\n",
    "test_cite_inputs_id = test_cite_inputs_id.fillna(0)\n",
    "test_cite_svd_clr = test_cite_inputs_id.drop(['cell_id'],axis=1).values\n",
    "\n",
    "print('cite_inputs_bio_norm_svd_100')\n",
    "cite_inputs_bio_norm_2_svd = np.load(feature_path+'cite_inputs_bio_norm_svd_100.npy')\n",
    "train_cite_inputs_bio_norm_2_svd = cite_inputs_bio_norm_2_svd[:len(train_df)]\n",
    "test_cite_inputs_bio_norm_2_svd = cite_inputs_bio_norm_2_svd[len(train_df):]\n",
    "\n",
    "df_test_cite_inputs_bio_norm_2_svd = pd.DataFrame(test_cite_inputs_bio_norm_2_svd)\n",
    "df_test_cite_inputs_bio_norm_2_svd['cell_id'] = test_cite_inputs_raw['cell_id']\n",
    "test_cite_inputs_id = test_cite_inputs.copy()\n",
    "test_cite_inputs_id = test_cite_inputs_id.merge(df_test_cite_inputs_bio_norm_2_svd, on=['cell_id'], how='left')\n",
    "test_cite_inputs_id = test_cite_inputs_id.fillna(0)\n",
    "test_cite_inputs_bio_norm_2_svd = test_cite_inputs_id.drop(['cell_id'],axis=1).values\n",
    "\n",
    "print('cite_inputs_raw_important_feats')\n",
    "cite_inputs_feats = np.load(feature_path+'cite_inputs_raw_important_feats.npy')  \n",
    "train_cite_inputs_feats = cite_inputs_feats[:len(train_df)]\n",
    "test_cite_inputs_feats = cite_inputs_feats[len(train_df):]\n",
    "\n",
    "df_test_cite_inputs_feats = pd.DataFrame(test_cite_inputs_feats)\n",
    "df_test_cite_inputs_feats['cell_id'] = test_cite_inputs_raw['cell_id']\n",
    "test_cite_inputs_id = test_cite_inputs.copy()\n",
    "test_cite_inputs_id = test_cite_inputs_id.merge(df_test_cite_inputs_feats, on=['cell_id'], how='left')\n",
    "test_cite_inputs_id = test_cite_inputs_id.fillna(0)\n",
    "test_cite_inputs_feats = test_cite_inputs_id.drop(['cell_id'],axis=1).values\n",
    "\n",
    "print('cite_inputs_bio_norm_pca_64')\n",
    "cite_inputs_bio_norm_pca_64 = np.load(feature_path+'cite_inputs_bio_norm_pca_64.npy')\n",
    "train_cite_inputs_bio_norm_pca_64 = cite_inputs_bio_norm_pca_64[:len(train_df)]\n",
    "test_cite_inputs_bio_norm_pca_64 = cite_inputs_bio_norm_pca_64[len(train_df):]\n",
    "\n",
    "df_test_cite_inputs_bio_norm_pca_64 = pd.DataFrame(test_cite_inputs_bio_norm_pca_64)\n",
    "df_test_cite_inputs_bio_norm_pca_64['cell_id'] = test_cite_inputs_raw['cell_id']\n",
    "test_cite_inputs_id = test_cite_inputs.copy()\n",
    "test_cite_inputs_id = test_cite_inputs_id.merge(df_test_cite_inputs_bio_norm_pca_64, on=['cell_id'], how='left')\n",
    "test_cite_inputs_id = test_cite_inputs_id.fillna(0)\n",
    "test_cite_inputs_bio_norm_pca_64 = test_cite_inputs_id.drop(['cell_id'],axis=1).values\n",
    "\n",
    "\n",
    "print('concatenate')\n",
    "train_cite_X = np.concatenate([\n",
    "                               train_cite_svd_clr,\n",
    "                               train_cite_inputs_feats,\n",
    "                               train_cite_inputs_bio_norm_2_svd,\n",
    "                               train_cite_inputs_bio_norm_pca_64,\n",
    "                                ],axis=1)\n",
    "\n",
    "test_cite_X = np.concatenate([\n",
    "                              test_cite_svd_clr,\n",
    "                              test_cite_inputs_feats,\n",
    "                              test_cite_inputs_bio_norm_2_svd,\n",
    "                              test_cite_inputs_bio_norm_pca_64\n",
    "                                ],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ====================================================\n",
    "# lightgbm\n",
    "# ====================================================\n",
    "def lgb_kfold(train_df, test_df, train_cite_X, train_cite_y, test_cite_X, folds):\n",
    "    params = {    \n",
    "        'objective' : 'rmse',\n",
    "        'metric' : 'mse', \n",
    "         'num_leaves': 33,\n",
    "         'min_data_in_leaf': 30,\n",
    "         'learning_rate': 0.01,\n",
    "         'max_depth': 7,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"lambda_l1\":0.1,\n",
    "         \"lambda_l2\":1,\n",
    "         \"verbosity\": -1,        \n",
    "                 }      \n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df)): \n",
    "        print ('n_fold:',n_fold)\n",
    "        train_x = train_cite_X[train_idx]\n",
    "        valid_x = train_cite_X[valid_idx]\n",
    "        train_y = train_cite_y[train_idx]\n",
    "        valid_y = train_cite_y[valid_idx]\n",
    "\n",
    "        dtrain = lgb.Dataset(\n",
    "            train_x, label=train_y,)\n",
    "        dval = lgb.Dataset(\n",
    "            valid_x, label=valid_y, reference=dtrain,)\n",
    "        bst = lgb.train(\n",
    "            params, dtrain, num_boost_round=10000,\n",
    "            valid_sets=[dval],verbose_eval=1000, early_stopping_rounds=100,\n",
    "        )\n",
    "\n",
    "        oof_preds[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n",
    "        sub_preds += bst.predict(test_cite_X, num_iteration=bst.best_iteration) / folds.n_splits         \n",
    "        \n",
    "    return oof_preds,sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 666\n",
    "folds = KFold(n_splits= 5, shuffle=True, random_state=seed)  \n",
    "train_preds = []\n",
    "test_preds = []\n",
    "for i in range(140):\n",
    "    print('=====================')\n",
    "    print(i)\n",
    "    train_cite_y_single = train_cite_y[:,i]\n",
    "    oof_preds,sub_preds = lgb_kfold(train_df, test_df, train_cite_X, train_cite_y_single, test_cite_X, folds)\n",
    "    train_preds.append(oof_preds)\n",
    "    test_preds.append(sub_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)\n",
    "\n",
    "oof_preds = np.zeros((len(train_df), 140))\n",
    "for n in range(len(train_preds)):\n",
    "    oof_preds[:,n] =  train_preds[n]\n",
    "\n",
    "cv = correlation_score(train_cite_y, oof_preds)\n",
    "print (cv)\n",
    "\n",
    "sub_preds = np.zeros((len(test_df), 140))\n",
    "for n in range(len(test_preds)):\n",
    "    sub_preds[:,n] =  test_preds[n]  \n",
    "\n",
    "lgb2 = np.concatenate([oof_preds,sub_preds],axis=0)\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=100, algorithm='arpack')\n",
    "lgb2_svd = tsvd.fit_transform(lgb2)\n",
    "np.save(feature_path+'cite_lgb2_svd_100.npy', lgb2_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
